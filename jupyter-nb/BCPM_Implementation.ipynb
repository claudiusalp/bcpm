{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.special as sp\n",
    "import os\n",
    "import copy\n",
    "import heapq\n",
    "import json\n",
    "\n",
    "def find_or_create(dirname):\n",
    "    if not os.path.isdir(dirname):\n",
    "        try:\n",
    "            os.makedirs(dirname)\n",
    "        except:\n",
    "            print(\"Cannot create directory : \" + dirname)\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def load_txt(filename):\n",
    "    X = np.loadtxt(filename)\n",
    "    dim = int(X[0]);\n",
    "    size = []\n",
    "    for i in range(dim):\n",
    "        size.append(int(X[i+1]));    \n",
    "    X = np.reshape(X[dim+1:], size, order='F')\n",
    "    return X;\n",
    "        \n",
    "def save_txt(filename, X):\n",
    "    with open(filename, 'w') as f:\n",
    "        y = np.asarray(X)\n",
    "        dim = len(y.shape)\n",
    "        f.write('%d\\n' % dim)\n",
    "        for i in range(dim):\n",
    "            f.write('%d\\n' % y.shape[i])\n",
    "        temp = y.reshape(np.product(y.shape), order='F')\n",
    "        for num in temp:\n",
    "            f.write(str(num)+\"\\n\")\n",
    "        \n",
    "        \n",
    "def normalize(x):\n",
    "    sum_x = np.sum(x)\n",
    "    return np.asarray(x) / sum_x\n",
    "\n",
    "\n",
    "def normalize_exp(x):\n",
    "    return normalize(np.exp(x - np.max(x)))\n",
    "\n",
    "\n",
    "def log_sum_exp(x):\n",
    "    max_x = np.max(x)\n",
    "    return max_x + np.log(np.sum(np.exp(x-max_x)))\n",
    "\n",
    "\n",
    "def psi(x):\n",
    "    return sp.digamma(x)\n",
    "\n",
    "\n",
    "def inv_psi(y):\n",
    "    x = (np.exp(y) + 0.5) * (y > -2.22) + (-1 / (y + 0.577215)) * (y <= -2.22)\n",
    "    for i in range(5):\n",
    "        x = x - ((sp.digamma(x) - y) / sp.polygamma(1, x))\n",
    "    return x\n",
    "\n",
    "\n",
    "def gammaln(x):\n",
    "    return sp.gammaln(x)\n",
    "\n",
    "\n",
    "class Data:\n",
    "    def __init__(self, s=(), h=(), v=()):\n",
    "        self.s = np.asarray(s)\n",
    "        self.h = np.asarray(h)\n",
    "        self.v = np.asarray(v)\n",
    "\n",
    "    def save(self, dirname):\n",
    "        find_or_create(dirname)\n",
    "        if self.s.size > 0:\n",
    "            save_txt(dirname + '/cps.txt', self.s)\n",
    "        if self.h.size > 0:\n",
    "            save_txt(dirname + '/states.txt', self.h)\n",
    "        if self.v.size > 0:\n",
    "            save_txt(dirname + '/obs.txt', self.v)\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, dirname):\n",
    "        data = cls()\n",
    "        filename = dirname + '/cps.txt'\n",
    "        if os.path.isfile(filename):\n",
    "            data.s = load_txt(filename)\n",
    "        filename = dirname + '/states.txt'\n",
    "        if os.path.isfile(filename):\n",
    "            data.h = load_txt(filename)\n",
    "        filename = dirname + '/obs.txt'\n",
    "        if os.path.isfile(filename):\n",
    "            data.v = load_txt(filename)\n",
    "        return data\n",
    "\n",
    "\n",
    "class Result:\n",
    "    def __init__(self):\n",
    "        self.cpp = []\n",
    "        self.mean = []\n",
    "        self.ll = []\n",
    "\n",
    "    def save(self, dirname):\n",
    "        find_or_create(dirname)\n",
    "        if len(self.mean) > 0:\n",
    "            save_txt(dirname + '/mean.txt', self.mean)\n",
    "        if len(self.cpp) > 0:\n",
    "            save_txt(dirname + '/cpp.txt', self.cpp)\n",
    "        if len(self.ll) > 0:\n",
    "            save_txt(dirname + '/ll.txt', self.ll)\n",
    "            \n",
    "    @classmethod\n",
    "    def load(cls, dirname):\n",
    "        result = cls()\n",
    "        filename = dirname + '/cpp.txt'\n",
    "        if os.path.isfile(filename):\n",
    "            result.cpp = load_txt(filename)\n",
    "        filename = dirname + '/mean.txt'\n",
    "        if os.path.isfile(filename):\n",
    "            result.mean = load_txt(filename)\n",
    "        filename = dirname + '/ll.txt'\n",
    "        if os.path.isfile(filename):\n",
    "            result.ll = load_txt(filename)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import sys\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def visualize_data(dirname, m, n):\n",
    "    data = Data.load(dirname)\n",
    "    t = data.v.shape[1]\n",
    "    if m > 0:\n",
    "        fig = plt.figure(figsize=(12, 4))\n",
    "        ax = fig.gca()\n",
    "        ax.pcolormesh(data.v[0:m, :], cmap=plt.cm.Greys)\n",
    "        ax.vlines(np.arange(0, t), 0, data.s * m, colors='r', linestyles='-', linewidth=2)\n",
    "        ax.legend(['change points'])\n",
    "    if n > 0:\n",
    "        fig = plt.figure(figsize=(12, 4))\n",
    "        gs = gridspec.GridSpec(n, 1, height_ratios=np.ones(n))\n",
    "        for i in range(n):\n",
    "            ax = plt.subplot(gs[i])\n",
    "            y = data.v[m + i, :]\n",
    "            y_lim_max = np.max(y) * 1.1\n",
    "            # ax.plot(range(t), y, 'b-')\n",
    "            ax.vlines(np.arange(t), np.zeros(t), y)\n",
    "            ax.vlines(np.arange(0, t), 0, data.s * y_lim_max, colors='r', linestyles='-', linewidth=2)\n",
    "            ax.set_ylim([0, y_lim_max])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Potential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Potential:\n",
    "    def __init__(self, alpha=(), a=(), b=(), log_c=0):\n",
    "        self.alpha = np.asarray(alpha, dtype=float)\n",
    "        self.a = np.asarray(a, dtype=float)\n",
    "        self.b = np.asarray(b, dtype=float)\n",
    "        self.log_c = log_c\n",
    "\n",
    "    def __lt__(self, other):\n",
    "        return self.log_c < other.log_c\n",
    "\n",
    "    def __gt__(self, other):\n",
    "        return self.log_c > other.log_c\n",
    "\n",
    "    def __mul__(self, other):\n",
    "        p = copy.deepcopy(self)\n",
    "        p.log_c += other.log_c\n",
    "        # Multiply Dirichlet component\n",
    "        if len(self.alpha) > 0:\n",
    "            p.alpha = self.alpha + other.alpha - 1\n",
    "            p.log_c += gammaln(np.sum(self.alpha)) - np.sum(gammaln(self.alpha))\n",
    "            p.log_c += gammaln(np.sum(other.alpha)) - np.sum(gammaln(other.alpha))\n",
    "            p.log_c += np.sum(gammaln(p.alpha)) - gammaln(np.sum(p.alpha))\n",
    "        # Multiply Gamma components\n",
    "        if len(self.a) > 0:\n",
    "            p.a = self.a + other.a - 1\n",
    "            p.b = (self.b * other.b) / (self.b + other.b)\n",
    "            p.log_c += np.sum(gammaln(p.a) + p.a * np.log(p.b))\n",
    "            p.log_c -= np.sum(gammaln(self.a) + self.a * np.log(self.b))\n",
    "            p.log_c -= np.sum(gammaln(other.a) + other.a * np.log(other.b))\n",
    "        return p\n",
    "\n",
    "    def __str__(self):\n",
    "        np.set_printoptions(precision=3)\n",
    "        buffer = np.concatenate((self.alpha, self.a, self.b, [self.log_c]))\n",
    "        return str(buffer)\n",
    "\n",
    "    @classmethod\n",
    "    def default(cls, m, n):\n",
    "        return cls(np.ones(m), np.ones(n) * 10, np.ones(n), 0)\n",
    "\n",
    "    @classmethod\n",
    "    def from_observation(cls, obs, m, n):\n",
    "        p = cls()\n",
    "        if m > 0:\n",
    "            sum_obs = np.sum(obs[0:m])\n",
    "            p.log_c = gammaln(sum_obs+1) - gammaln(sum_obs+m)\n",
    "            p.alpha = np.asarray(obs[0:m]) + 1\n",
    "        if n > 0:\n",
    "            p.a = np.asarray(obs[m:]) +1\n",
    "            p.b = np.ones(n)\n",
    "        return p\n",
    "\n",
    "    def size(self):\n",
    "        return self.alpha.size + self.a.size\n",
    "\n",
    "    def copy(self):\n",
    "        return copy.deepcopy(self)\n",
    "\n",
    "    def rand(self):\n",
    "        x = np.ndarray(0)\n",
    "        if len(self.alpha) > 0:\n",
    "            x = np.random.dirichlet(self.alpha)\n",
    "        if len(self.a) > 0:\n",
    "            x = np.concatenate((x, np.random.gamma(self.a, self.b, self.a.shape)))\n",
    "        return x\n",
    "\n",
    "    def mean(self):\n",
    "        m = np.ndarray(0)\n",
    "        if len(self.alpha) > 0:\n",
    "            m = normalize(self.alpha)\n",
    "        if len(self.a) > 0:\n",
    "            m = np.concatenate((m, self.a * self.b))\n",
    "        return m\n",
    "\n",
    "    def get_ss(self):\n",
    "        ss = np.ndarray(0)\n",
    "        if len(self.alpha) > 0:\n",
    "            ss = psi(self.alpha) - psi(np.sum(self.alpha))\n",
    "        if len(self.a) > 0:\n",
    "            ss = np.concatenate((ss, self.a * self.b, psi(self.a) + np.log(self.b)))\n",
    "        return ss\n",
    "\n",
    "    def fit(self, ss):\n",
    "        m = len(self.alpha)\n",
    "        n = len(self.a)\n",
    "        if m > 0:\n",
    "            self.alpha = fit_dirichlet_from_ss(ss[0:m])\n",
    "        for i in range(n):\n",
    "            [self.a[i], self.b[i]] = fit_gamma_from_ss([ss[m+i], ss[m+i+n]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Message:\n",
    "\n",
    "    def __init__(self, max_k=100):\n",
    "        self.potentials = []  # potentials\n",
    "        self.h = []           # heap for fast pruning\n",
    "        self.max_k = max_k    # max capacity\n",
    "\n",
    "    def __mul__(self, other):\n",
    "        message = Message()\n",
    "        for p1 in self.potentials:\n",
    "            for p2 in other.potentials:\n",
    "                message.potentials.append(p1 * p2)\n",
    "        return message\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.potentials)\n",
    "\n",
    "    def add_potential(self, p):\n",
    "        k = len(self.potentials)\n",
    "        if k == self.max_k:\n",
    "            k = heapq.heappop(self.h)[1]\n",
    "            self.potentials[k] = p\n",
    "        else:\n",
    "            self.potentials.append(p)\n",
    "        if k > 0:\n",
    "            # push no-change message to heap\n",
    "            heapq.heappush(self.h, (p.log_c, k))\n",
    "\n",
    "    # p(potential)\n",
    "    def pp(self):\n",
    "        return normalize_exp(self.log_c())\n",
    "\n",
    "    # first k potentials belong to change probabilities\n",
    "    def cpp(self, k=1):\n",
    "        return np.sum(self.pp()[:k])\n",
    "\n",
    "    def log_likelihood(self):\n",
    "        return log_sum_exp(self.log_c())\n",
    "\n",
    "    def log_c(self):\n",
    "        return np.asarray([p.log_c for p in self.potentials])\n",
    "\n",
    "    def mean(self):\n",
    "        m = np.asarray([p.mean() for p in self.potentials])\n",
    "        return np.dot(m.transpose(), self.pp())\n",
    "\n",
    "    def get_ss(self):\n",
    "        ss = np.asarray([p.get_ss() for p in self.potentials])\n",
    "        return np.dot(ss.transpose(), self.pp())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, p1, alpha, a, b):\n",
    "        self.p1 = None      # prob. of change\n",
    "        self.log_p1 = None  # log prob. of change\n",
    "        self.log_p0 = None  # log prob. no change\n",
    "        self.set_p1(p1)\n",
    "        self.prior = Potential(alpha, a, b)\n",
    "        self.m = len(alpha)\n",
    "        self.n = len(a)\n",
    "\n",
    "    def set_p1(self, p1):\n",
    "        self.p1 = p1\n",
    "        self.log_p1 = np.log(p1)\n",
    "        self.log_p0 = np.log(1-p1)\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, filename):\n",
    "        buffer = load_txt(filename)\n",
    "        p1 = buffer[0]\n",
    "        m = int(buffer[1])\n",
    "        n = int(buffer[2])\n",
    "        alpha = buffer[3:m+3]\n",
    "        a = buffer[3+m:3+m+n]\n",
    "        b = buffer[3+m+n:3+m+n+n]\n",
    "        return cls(p1, alpha, a, b)\n",
    "\n",
    "    @classmethod\n",
    "    def default_model(cls, p1, m, n):\n",
    "        alpha = np.ones(m)\n",
    "        a = np.ones(n) * 10\n",
    "        b = np.ones(n) * 1\n",
    "        return cls(p1, alpha, a, b)\n",
    "\n",
    "    def save(self, filename):\n",
    "        buffer = np.concatenate(([self.p1, self.m, self.n], self.prior.alpha, self.prior.a, self.prior.b))\n",
    "        save_txt(filename, buffer)\n",
    "\n",
    "    def generate_data(self, t):\n",
    "        s = np.random.binomial(1, self.p1, t)               # change points\n",
    "        h = np.zeros((self.m + self.n, t))    # hidden states\n",
    "        v = np.zeros((self.m + self.n, t))    # observations\n",
    "        for i in range(t):\n",
    "            if i == 0 or s[i] == 1:\n",
    "                # generate random state:\n",
    "                h[:, i] = self.prior.rand()\n",
    "            else:\n",
    "                # copy previous state\n",
    "                h[:, i] = h[:, i-1]\n",
    "            # generate observation\n",
    "            v[:, i] = self.rand_obs(h[:, i])\n",
    "        return Data(s, h, v)\n",
    "\n",
    "    def rand_obs(self, state):\n",
    "        obs = np.asarray([])\n",
    "        if self.m > 0:\n",
    "            obs = np.random.multinomial(100, state[0:self.m])\n",
    "        if self.n > 0:\n",
    "            obs = np.concatenate((obs, np.random.poisson(state[self.m:])))\n",
    "        return obs\n",
    "\n",
    "    def predict(self, alpha):\n",
    "        m = Message()\n",
    "        # add change component\n",
    "        m.add_potential(Potential(self.prior.alpha, self.prior.a, self.prior.b, self.log_p1 + alpha.log_likelihood()))\n",
    "        # add no-change components\n",
    "        for p in alpha.potentials:\n",
    "            m.add_potential(Potential(p.alpha, p.a, p.b, p.log_c + self.log_p0))\n",
    "        return m\n",
    "\n",
    "    def update(self, predict, obs):\n",
    "        m = Message()\n",
    "        p_obs = Potential.from_observation(obs, self.m, self.n)\n",
    "        for p in predict.potentials:\n",
    "            m.add_potential(p * p_obs)\n",
    "        return m\n",
    "\n",
    "    def forward(self, obs):\n",
    "        alpha = []\n",
    "        alpha_predict = []\n",
    "        for i in range(obs.shape[1]):\n",
    "            if i == 0:\n",
    "                m = Message()\n",
    "                m.add_potential(Potential(self.prior.alpha, self.prior.a, self.prior.b, self.log_p1))\n",
    "                m.add_potential(Potential(self.prior.alpha, self.prior.a, self.prior.b, self.log_p0))\n",
    "                alpha_predict.append(m)\n",
    "            else:\n",
    "                alpha_predict.append(self.predict(alpha[-1]))\n",
    "            alpha.append(self.update(alpha_predict[-1], obs[:, i]))\n",
    "        return [alpha_predict, alpha]\n",
    "\n",
    "    def backward(self, obs, start=0, length=0):\n",
    "        if length == 0:\n",
    "            length = obs.shape[1]\n",
    "            start = length-1\n",
    "        beta = []\n",
    "        for i in range(start, start - length, -1):\n",
    "            message = Message()\n",
    "            temp = Message()\n",
    "            p_obs = Potential.from_observation(obs[:, i], self.m, self.n)\n",
    "            # change\n",
    "            if len(beta) > 0:\n",
    "                for p in beta[-1].potentials:\n",
    "                    temp.add_potential(p * p_obs)\n",
    "                p_obs.log_c += self.log_p1 + temp.log_likelihood()\n",
    "            message.add_potential(p_obs)\n",
    "            # no change\n",
    "            if len(beta) > 0:\n",
    "                for p in temp.potentials:\n",
    "                    p.log_c += self.log_p0\n",
    "                    message.add_potential(Potential(p.alpha, p.a, p.b, p.log_c))\n",
    "            beta.append(message)\n",
    "        beta.reverse()\n",
    "        return beta\n",
    "\n",
    "    def filter(self, obs):\n",
    "        alpha = self.forward(obs)[1]\n",
    "        # compile result\n",
    "        result = Result()\n",
    "        result.cpp = [message.cpp() for message in alpha]\n",
    "        result.mean = [message.mean() for message in alpha]\n",
    "        result.ll = [alpha[-1].log_likelihood()]\n",
    "        return result\n",
    "\n",
    "    def smooth(self, obs):\n",
    "        [alpha_predict, alpha] = self.forward(obs)\n",
    "        beta = self.backward(obs)\n",
    "        # compile result\n",
    "        result = Result()\n",
    "        for i in range(len(alpha)):\n",
    "            gamma = alpha_predict[i] * beta[i]\n",
    "            result.cpp.append(gamma.cpp(len(beta[i].potentials)))\n",
    "            result.mean.append(gamma.mean())\n",
    "        result.ll = [alpha[-1].log_likelihood()]\n",
    "        return result\n",
    "\n",
    "    def online_smooth(self, obs, lag):\n",
    "        if lag == 0:\n",
    "            return self.filter(obs)\n",
    "\n",
    "        t = obs.shape[1]\n",
    "        if lag >= t:\n",
    "            return self.smooth(obs)\n",
    "\n",
    "        result = Result()\n",
    "        [alpha_predict, alpha] = self.forward(obs)\n",
    "        beta = []\n",
    "\n",
    "        # Run Fixed-Lag for alpha[0:T - lag]\n",
    "        for i in range(t - lag + 1):\n",
    "            beta = self.backward(obs, i + lag - 1, lag)\n",
    "            gamma = alpha_predict[i] * beta[0]\n",
    "            result.cpp.append(gamma.cpp(len(beta[0])))\n",
    "            result.mean.append(gamma.mean())\n",
    "\n",
    "        # Smooth alpha[T-lag+1:T] with last beta.\n",
    "        for i in range(1, lag):\n",
    "            gamma = alpha_predict[t - lag + i] * beta[i]\n",
    "            result.cpp.append(gamma.cpp(len(beta[i])))\n",
    "            result.mean.append(gamma.mean())\n",
    "\n",
    "        result.ll = [alpha[-1].log_likelihood()]\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".......\n",
      "----------------------------------------------------------------------\n",
      "Ran 7 tests in 0.004s\n",
      "\n",
      "OK\n",
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.006s\n",
      "\n",
      "OK\n",
      "..\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.005s\n",
      "\n",
      "OK\n",
      "......\n",
      "----------------------------------------------------------------------\n",
      "Ran 6 tests in 0.003s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "import unittest\n",
    "\n",
    "class TestUtils(unittest.TestCase):\n",
    "\n",
    "    def test_load_save(self):\n",
    "        x = np.random.rand(4, 5)\n",
    "        save_txt('/tmp/x.txt', x)\n",
    "        y = load_txt('/tmp/x.txt')\n",
    "        np.testing.assert_array_almost_equal(x, y)\n",
    "\n",
    "    def test_gammaln(self):\n",
    "        v = np.asarray([1, 2, 3, 4, 5])\n",
    "        gammaln_v = np.asarray([0, 0, 0.693147, 1.791759, 3.178053])\n",
    "        np.testing.assert_array_almost_equal(gammaln(v), gammaln_v)\n",
    "\n",
    "    def test_normalize(self):\n",
    "        v = np.asarray([1, 2, 3, 4, 5])\n",
    "        nv = np.asarray([0.066667, 0.133333, 0.2, 0.266667, 0.333333])\n",
    "        np.testing.assert_array_almost_equal(normalize(v), nv)\n",
    "\n",
    "    def test_normalize_exp(self):\n",
    "        v = np.asarray([1, 2, 3, 4, 5])\n",
    "        log_v = np.log(v)\n",
    "        np.testing.assert_array_almost_equal(normalize(v), normalize_exp(log_v))\n",
    "\n",
    "    def test_log_sum_exp(self):\n",
    "        v = np.asarray([1, 2, 3, 4, 5])\n",
    "        np.testing.assert_array_almost_equal(log_sum_exp(v), np.log(np.sum(np.exp(v))))\n",
    "\n",
    "    def test_psi(self):\n",
    "        v = np.asarray([1, 2, 3, 4, 5])\n",
    "        psi_v = np.asarray([-0.57721566, 0.42278434, 0.92278434, 1.25611767, 1.50611767])\n",
    "        np.testing.assert_array_almost_equal(psi(v), psi_v)\n",
    "\n",
    "    def test_inv_psi(self):\n",
    "        for x in [1e-6, 0.1, 1, 2, 1000]:\n",
    "            np.testing.assert_almost_equal(x, inv_psi(psi(x)))\n",
    "\n",
    "\n",
    "class TestData(unittest.TestCase):\n",
    "\n",
    "    def test_load_save(self):\n",
    "        t = 100\n",
    "        d = 5\n",
    "        data = Data(np.zeros(t), np.random.rand(t, d), np.random.rand(t, d))\n",
    "        data.save('/tmp/data/')\n",
    "        data2 = Data.load('/tmp/data/')\n",
    "        np.testing.assert_array_almost_equal(data.s, data2.s)\n",
    "        np.testing.assert_array_almost_equal(data.h, data2.h)\n",
    "        np.testing.assert_array_almost_equal(data.v, data2.v)\n",
    "\n",
    "\n",
    "class TestModel(unittest.TestCase):\n",
    "\n",
    "    def test_load_save(self):\n",
    "        m = Model(0.01, [1, 1, 1, 1], [10, 10, 10], [1, 1, 1])\n",
    "        m.save('/tmp/model.txt')\n",
    "        m2 = Model.load('/tmp/model.txt')\n",
    "        self.assertEqual(m.p1, m2.p1)\n",
    "        np.testing.assert_array_almost_equal_nulp(m.prior.alpha, m2.prior.alpha)\n",
    "        np.testing.assert_array_almost_equal_nulp(m.prior.a, m2.prior.a)\n",
    "        np.testing.assert_array_almost_equal_nulp(m.prior.b, m2.prior.b)\n",
    "\n",
    "    def test_generate_data(self):\n",
    "        t = 100\n",
    "        # Generate Dirichlet only\n",
    "        m = Model(0.1, [1, 1, 1], [], [])\n",
    "        data = m.generate_data(t)\n",
    "        #data.save('/tmp/data1')\n",
    "\n",
    "        # Generate Gamma only\n",
    "        m2 = Model(0.1, [], [10, 10], [1, 1])\n",
    "        data2 = m2.generate_data(t)\n",
    "        #data2.save('/tmp/data2')\n",
    "\n",
    "        # Generate Coupled\n",
    "        m3 = Model(0.1, [1, 1, 1, 1], [10, 10], [1, 1])\n",
    "        data3 = m3.generate_data(t)\n",
    "        #data3.save('/tmp/data3')\n",
    "\n",
    "\n",
    "class TestPotential(unittest.TestCase):\n",
    "\n",
    "    def test_deepcopy(self):\n",
    "        p1 = Potential.default(3, 2)\n",
    "        p2 = p1.copy()\n",
    "\n",
    "        p2.alpha = np.asarray([1, 2, 3])\n",
    "        p2.a = np.asarray([6, 7])\n",
    "        p2.b = np.asarray([2, 3])\n",
    "        p2.log_c = 2\n",
    "        self.assertNotEqual(p1.log_c, p2.log_c)\n",
    "\n",
    "    def test_comparison(self):\n",
    "        p1 = Potential.default(3, 2)\n",
    "        p2 = Potential.default(3, 2)\n",
    "        p2.log_c = 2\n",
    "        self.assertTrue(p1 < p2)\n",
    "        self.assertTrue(p2 > p1)\n",
    "\n",
    "    def test_multiplication(self):\n",
    "        # Part 1: Test Dirichlet multiplication\n",
    "        p1 = Potential([1, 2, 3, 4], [], [])\n",
    "        p2 = Potential([5, 6, 7, 8], [], [])\n",
    "        p3 = p1 * p2\n",
    "        np.testing.assert_almost_equal(p3.log_c, 2.62466487)\n",
    "        np.testing.assert_array_almost_equal(p3.alpha, np.asarray([5, 7, 9, 11]))\n",
    "\n",
    "        # Part 2: Test Gamma multiplication\n",
    "        p1 = Potential([], [10], [1])\n",
    "        p2 = Potential([], [5], [2])\n",
    "        p3 = p1 * p2\n",
    "        np.testing.assert_almost_equal(p3.log_c, -2.56996487)\n",
    "        np.testing.assert_almost_equal(p3.a, 14)\n",
    "        np.testing.assert_almost_equal(p3.b, 0.66666667)\n",
    "\n",
    "        # Part 2: Test Coupled multiplication\n",
    "        p1 = Potential([1, 2, 3, 4], [10], [1])\n",
    "        p2 = Potential([5, 6, 7, 8], [5], [2])\n",
    "        p3 = p1 * p2\n",
    "        np.testing.assert_almost_equal(p3.log_c, 2.62466487 - 2.56996487)\n",
    "        np.testing.assert_array_almost_equal(p3.alpha, np.asarray([5, 7, 9, 11]))\n",
    "        np.testing.assert_almost_equal(p3.a, 14)\n",
    "        np.testing.assert_almost_equal(p3.b, 0.66666667)\n",
    "\n",
    "    def test_from_observation(self):\n",
    "        obs = np.concatenate((normalize([2, 3, 4, 5]), [7]))\n",
    "        p = Potential.from_observation(obs, 4, 1)\n",
    "        np.testing.assert_array_almost_equal(p.alpha, np.asarray([1.142857, 1.214286, 1.285714, 1.357143]))\n",
    "        np.testing.assert_almost_equal(p.log_c, -3.17805383)\n",
    "        np.testing.assert_almost_equal(p.a, 8)\n",
    "        np.testing.assert_almost_equal(p.b, 1)\n",
    "\n",
    "    def test_mean(self):\n",
    "        p = Potential([1, 2, 3, 4], [10], [1])\n",
    "        np.testing.assert_array_almost_equal(p.mean(), np.asarray([0.1, 0.2, 0.3, 0.4, 10]))\n",
    "\n",
    "    def test_ss(self):\n",
    "        p = Potential([1, 2, 3, 4], [10], [1])\n",
    "        ss = np.asarray([-2.828968, -1.828968, -1.328968, -0.995635, 10., 2.251753])\n",
    "        np.testing.assert_array_almost_equal(p.get_ss(), ss)\n",
    "\n",
    "    '''\n",
    "    def test_rand_and_fit(self):\n",
    "        p = Potential([1, 2, 3, 4], [10, 5], [1, 2])\n",
    "        n = 1000\n",
    "        x = np.zeros((n, 6))\n",
    "        for i in range(n):\n",
    "            x[i, :] = p.rand()\n",
    "        ss1 = np.mean(np.log(x[:, 0:4]), axis=0)\n",
    "        ss2 = np.concatenate((np.mean(x[:, 4:6], axis=0), np.mean(np.log(x[:, 4:6]), axis=0)))\n",
    "        ss = np.concatenate((ss1, ss2))\n",
    "        p2 = Potential.default(4,2)\n",
    "        p2 = p.copy()\n",
    "        p2.fit(ss)\n",
    "   ''' \n",
    "\n",
    "def run_tests():\n",
    "    for m in (TestUtils(),TestData(), TestModel(), TestPotential()):\n",
    "        suite = unittest.TestLoader().loadTestsFromModule(m)\n",
    "        unittest.TextTestRunner().run(suite)\n",
    "        \n",
    "# Comment in for running unit tests\n",
    "run_tests()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo & Python-C++ Comparison\n",
    "\n",
    "The test below compares the results of the C++ and Python implementations of the Change Point Model. The expectation is that both models give almost equal change point probabilities and expected means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtering...\n",
      "smoothing...\n",
      "online smoothing...\n",
      "Compiling C++ codes...\n",
      "Running C++ codes...\n",
      "C++ and Python results are almost equal by 5 decimal points.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsYAAAEACAYAAACwMbCBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWHwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe853d5aac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsMAAAD7CAYAAACPOpmrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/w/Vnc9GjiVHzAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe853c50898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def test_cpp_python():\n",
    "    bcpm_root = \"../\"\n",
    "    work_dir = '/tmp/demo'\n",
    "    find_or_create(work_dir)\n",
    "    \n",
    "    # save python results\n",
    "    data_dir = os.path.join(work_dir, 'data')\n",
    "    python_dir = os.path.join(work_dir, 'python')\n",
    "    cpp_dir = os.path.join(work_dir, 'cpp')\n",
    "\n",
    "    # Generate Model\n",
    "    t = 30\n",
    "    p1 = 0.05\n",
    "    m = 4\n",
    "    n = 3\n",
    "    model = Model.default_model(p1, m, n)\n",
    "    model.save(work_dir + '/model.txt')\n",
    "\n",
    "    # Generate Data\n",
    "    data = model.generate_data(t)\n",
    "    data.save(data_dir)\n",
    "\n",
    "    # Change Point Estimations\n",
    "    print('filtering...')\n",
    "    result_f = model.filter(data.v)\n",
    "    result_f.save(python_dir + '/filtering')\n",
    "\n",
    "    print('smoothing...')\n",
    "    result_s = model.smooth(data.v)\n",
    "    result_s.save(python_dir + '/smoothing')\n",
    "\n",
    "    print('online smoothing...')\n",
    "    result_o = model.online_smooth(data.v, lag=10)\n",
    "    result_o.save(python_dir + '/online_smoothing')\n",
    " \n",
    "    # Compile c++ code\n",
    "    print('Compiling C++ codes...')\n",
    "    os.system(\"(cd ../cpp/; ./compile)\")\n",
    "    print('Running C++ codes...')\n",
    "    os.system(\"(cd \" + bcpm_root + \"/cpp/bin/; ./runner \" + work_dir + \")\")\n",
    "\n",
    "    cpp_result_f = Result.load(os.path.join(cpp_dir, 'filtering'))\n",
    "    np.testing.assert_array_almost_equal(cpp_result_f.cpp, result_f.cpp, decimal=5)\n",
    "    np.testing.assert_array_almost_equal(cpp_result_f.ll, result_f.ll, decimal=5)\n",
    "\n",
    "    cpp_result_s = Result.load(os.path.join(cpp_dir, 'smoothing'))\n",
    "    np.testing.assert_array_almost_equal(cpp_result_s.cpp, result_s.cpp, decimal=5)\n",
    "    np.testing.assert_array_almost_equal(cpp_result_s.ll, result_s.ll, decimal=5)\n",
    "\n",
    "    cpp_result_o = Result.load(os.path.join(cpp_dir, 'online_smoothing'))\n",
    "    np.testing.assert_array_almost_equal(cpp_result_o.cpp, result_o.cpp, decimal=5)\n",
    "    np.testing.assert_array_almost_equal(cpp_result_o.ll, result_o.ll, decimal=5)\n",
    "    \n",
    "    print('C++ and Python results are almost equal by 5 decimal points.')\n",
    "    \n",
    "    # Visualization\n",
    "    visualize_data(data_dir, m, n)\n",
    "\n",
    "    \n",
    "# Comment in for running C++ vs Python Test\n",
    "test_cpp_python()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
